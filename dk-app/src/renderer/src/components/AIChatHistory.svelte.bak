<script lang="ts">
  import { cn } from '@lib/utils'
  import { onMount, onDestroy, afterUpdate } from 'svelte'
  import {
    Bot,
    User,
    ArrowRight,
    LoaderCircle,
    Copy,
    CheckCircle,
    MoreVertical,
    Trash2,
    Server,
    FileText
  } from 'lucide-svelte'
  import { formatMessageTimestamp } from '@lib/utils/format'
  import * as SharedTypes from '@shared/types'
  type AIMessage = SharedTypes.AIMessage
  import * as LLMTypes from '@shared/llmTypes'
  // Alias types for easier use
  type ChatCompletionRequest = LLMTypes.ChatCompletionRequest
  type StreamingChunk = LLMTypes.StreamingChunk
  type ChatCompletionResponse = LLMTypes.ChatCompletionResponse
  type LLMProvider = LLMTypes.LLMProvider
  import logger from '@lib/utils/logger'
  import { safeIpcCall } from '@lib/utils/errorHandler'
  import { AppError, ErrorType } from '@shared/errors'

  // Import simple command system
  import SimpleCommandPopup from './ui/SimpleCommandPopup.svelte'
  import UserMentionPopup from './ui/UserMentionPopup.svelte'
  import MCPServersModal from './MCPServersModal.svelte'
  import DocumentModal from './DocumentModal.svelte'
  import {
    commandPopupVisible,
    showCommandPopup,
    hideCommandPopup,
    executeCommand,
    filterCommands
  } from '@lib/commands'
  import { clsx } from 'clsx'
  
  // User mention system
  let userMentionPopupVisible = false
  let selectedUserIndex = 0

  // Reference to the chat container for auto-scrolling
  let chatContainer: HTMLElement

  // Initial welcome message
  let messages: AIMessage[] = [
    {
      id: crypto.randomUUID(),
      role: 'assistant',
      content: "Hello! I'm your AI assistant. How can I help you today?",
      timestamp: new Date()
    }
  ]

  let newMessageText = ''
  let isWaitingForResponse = false
  let activeProvider: LLMProvider | '' = ''
  let availableProviders: LLMProvider[] = []
  let activeModel: string = ''
  let availableModels: string[] = []
  let requestId = ''

  // Initialize LLM-related data
  async function initLLMData() {
    try {
      logger.debug('Initializing LLM data...')

      availableProviders = (await window.api.llm.getProviders()) || []
      logger.debug('Available providers:', availableProviders)

      activeProvider = (await window.api.llm.getActiveProvider()) || ''
      logger.debug('Active provider:', activeProvider)

      // Get models for the active provider
      if (activeProvider) {
        availableModels = (await window.api.llm.getModels()) || []
        logger.debug('Available models:', availableModels)

        // Get config to find the default model
        const config = await window.api.llm.getConfig()
        logger.debug('LLM config:', config)

        if (config?.providers?.[activeProvider]?.defaultModel) {
          activeModel = config.providers[activeProvider].defaultModel
          logger.debug('Using default model from config:', activeModel)
        } else if (availableModels.length > 0) {
          activeModel = availableModels[0]
          logger.debug('Using first available model:', activeModel)
        }
      } else {
        logger.debug('No active provider set')
      }
    } catch (error) {
      logger.error('Failed to initialize LLM data:', error)
    }
  }

  // Streaming message handlers
  function handleStreamChunk(
    event: Electron.IpcRendererEvent,
    streamRequestId: string,
    chunk: StreamingChunk
  ) {
    logger.debug(`Stream chunk received for requestId: ${streamRequestId}, current requestId: ${requestId}`)

    if (streamRequestId !== requestId) {
      logger.debug('Ignoring chunk for different requestId')
      return
    }

    logger.debug(`Processing stream chunk: ${JSON.stringify(chunk.delta)}`)

    // Find the placeholder message and update its content
    let updatedMessage = false;
    messages = messages.map((msg) => {
      if (msg.isLoading && msg.role === 'assistant') {
        updatedMessage = true;
        logger.debug(`Updating message ${msg.id} with chunk content`)
        return {
          ...msg,
          content: msg.content + (chunk.delta.content || ''),
          isLoading: true
        }
      }
      return msg
    })

    if (!updatedMessage) {
      logger.debug('No loading assistant message found to update with stream chunk')
    }
  }

  function handleStreamComplete(
    event: Electron.IpcRendererEvent,
    streamRequestId: string,
    response: ChatCompletionResponse
  ) {
    logger.debug(`Stream complete received for requestId: ${streamRequestId}, current requestId: ${requestId}`)

    if (streamRequestId !== requestId) {
      logger.debug('Ignoring completion for different requestId')
      return
    }

    logger.debug('Stream complete, updating message state')

    // Remove the loading state from the assistant message
    let updatedMessage = false;
    messages = messages.map((msg) => {
      if (msg.isLoading && msg.role === 'assistant') {
        updatedMessage = true;
        logger.debug(`Marking message ${msg.id} as complete`)
        return {
          ...msg,
          isLoading: false
        }
      }
      return msg
    })

    if (!updatedMessage) {
      logger.debug('No loading assistant message found to mark as complete')
    }

    isWaitingForResponse = false

    // Save to database via IPC
    logger.debug('Saving updated messages to history after stream completion')
    saveAIChatHistory(messages)
  }

  function handleStreamError(
    event: Electron.IpcRendererEvent,
    streamRequestId: string,
    error: string
  ) {
    logger.debug(`Stream error received for requestId: ${streamRequestId}, current requestId: ${requestId}`)

    if (streamRequestId !== requestId) {
      logger.debug('Ignoring error for different requestId')
      return
    }

    logger.error('Error streaming message:', error)

    // Update the error message
    let updatedMessage = false;
    messages = messages.map((msg) => {
      if (msg.isLoading && msg.role === 'assistant') {
        updatedMessage = true;
        logger.debug(`Updating message ${msg.id} with error: ${error}`)
        return {
          ...msg,
          content: `I'm sorry, I encountered an error: ${error}`,
          isLoading: false
        }
      }
      return msg
    })

    if (!updatedMessage) {
      logger.debug('No loading assistant message found to update with error')
    }

    isWaitingForResponse = false

    // Still save to database for error tracking
    logger.debug('Saving updated messages to history after stream error')
    saveAIChatHistory(messages)
  }

  // Save messages to database through main process
  async function saveAIChatHistory(chatHistory: AIMessage[]) {
    try {
      await safeIpcCall(
        () => window.api.llm.saveAIChatHistory(chatHistory),
        {
          show: (message, options) => window.api.toast.show(message, options)
        },
        'Failed to save chat history'
      )
    } catch (error) {
      // Error is already shown to user via toast from safeIpcCall
      logger.error('Failed to save chat history:', error)
    }
  }

  // Setup streaming message handlers
  function setupStreamHandlers() {
    logger.debug('Setting up stream handlers')
    if (!window.api?.llm?.onStreamChunk) {
      logger.error('Stream handlers not available on window.api.llm')
      return
    }

    // Clean up any existing handlers first to prevent duplicates
    cleanupStreamHandlers()

    // Setup new handlers
    window.api.llm.onStreamChunk(handleStreamChunk)
    window.api.llm.onStreamComplete(handleStreamComplete)
    window.api.llm.onStreamError(handleStreamError)

    logger.debug('Stream handlers set up successfully')
  }

  // Clean up event listeners
  function cleanupStreamHandlers() {
    logger.debug('Cleaning up stream handlers')
    if (window.api?.llm?.removeStreamListeners) {
      window.api.llm.removeStreamListeners(
        handleStreamChunk,
        handleStreamComplete,
        handleStreamError
      )
      logger.debug('Stream handlers cleaned up')
    } else {
      logger.debug('Cannot clean up stream handlers - removeStreamListeners not available')
    }
  }

  // References for command functionality
  let inputTextarea: HTMLTextAreaElement
  let userId = crypto.randomUUID() // For command context
  
  // Users data from API
  let users = []
  
  // Load users from API
  async function loadUsers() {
    try {
      // The actual API is window.api.sidebar.getUsers()
      logger.debug('Loading users from sidebar API...')
      const userList = await window.api.sidebar.getUsers()
      
      if (userList && Array.isArray(userList) && userList.length > 0) {
        users = userList
        logger.debug('Successfully loaded users:', users)
      } else {
        logger.warn('No users returned from API, using fallback data')
        // Use fallback data
        users = [
          { id: '1', name: 'Alice', online: true, status: 'online' },
          { id: '2', name: 'Bob', online: false, status: 'offline' },
          { id: '3', name: 'Charlie', online: true, status: 'online' }
        ]
      }
    } catch (error) {
      logger.error('Failed to load users:', error)
      // Fallback to some sample users if API fails
      users = [
        { id: '1', name: 'Alice', online: true, status: 'online' },
        { id: '2', name: 'Bob', online: false, status: 'offline' },
        { id: '3', name: 'Charlie', online: true, status: 'online' }
      ]
    }
    
    // Always log the current state of users after loading
    logger.debug('Current users array:', users)
    return users
  }

  // Initialize commands function
  async function initCommands() {
    logger.debug('Initializing command system')
    try {
      // Use the command initializer to load server commands if available
      await import('@lib/commands').then((commands) => {
        if (commands.initializeCommands) {
          return commands.initializeCommands()
        }
      })
      logger.debug('Command system initialized')
    } catch (error) {
      logger.error('Failed to initialize commands:', error)
    }
  }

  onMount(async () => {
    try {
      // Load conversation history from main process using safe IPC call
      const savedMessages = await safeIpcCall(
        () => window.api.llm.getAIChatHistory(),
        {
          show: (message, options) => window.api.toast.show(message, options)
        },
        'Failed to load chat history'
      )

      if (savedMessages && savedMessages.length > 0) {
        messages = savedMessages
      }
    } catch (error) {
      // Error already shown to user via toast from safeIpcCall
      logger.error('Failed to load AI chat history:', error)

      // Use default welcome message if loading fails
      messages = [
        {
          id: crypto.randomUUID(),
          role: 'assistant',
          content: "Hello! I'm your AI assistant. How can I help you today?",
          timestamp: new Date()
        }
      ]
    }

    // Initialize LLM data
    try {
      await initLLMData()
    } catch (error) {
      logger.error('Failed to initialize LLM data:', error)
      window.api.toast.show('Failed to initialize AI service. Some features may be unavailable.', {
        type: 'warning'
      })
    }

    // Load slash commands
    try {
      await initCommands()
      logger.debug('Slash commands initialized')
    } catch (error) {
      logger.error('Failed to initialize slash commands:', error)
    }
    
    // Load users for @ mentions
    try {
      await loadUsers()
      logger.debug('Users loaded for @ mentions:', users)
    } catch (error) {
      logger.error('Failed to load users for @ mentions:', error)
    }

    // Set up stream handlers
    setupStreamHandlers()
  })

  onDestroy(() => {
    cleanupStreamHandlers()
  })

  // Auto-scroll to bottom whenever messages change
  afterUpdate(() => {
    if (chatContainer) {
      chatContainer.scrollTo({
        top: chatContainer.scrollHeight,
        behavior: 'smooth'
      })
    }
  })

  // Function to send a message to the AI assistant
  async function sendMessage() {
    if (!newMessageText.trim() || isWaitingForResponse) return

    // Validation checks
    if (!activeProvider || !activeModel) {
      window.api.toast.show('No AI provider or model configured. Please check your LLM settings.', {
        type: 'error'
      })
      return
    }

    const userInput = newMessageText.trim();
    
    // 1. Check for '@' mentions
    if (userInput.includes('@')) {
      logger.debug('Message contains user mentions, processing:', userInput);
      try {
        // Process the mentions via IPC
        const mentionResult = await window.api.llm.processMentions({
          prompt: userInput,
          userId: userId
        });
        
        // Extended debug logging to see exact structure
        logger.debug('Mention processing result:', JSON.stringify(mentionResult));
        console.log('Raw mentionResult:', mentionResult);
        
        // Add user message to chat
        const userMessage: AIMessage = {
          id: crypto.randomUUID(),
          role: 'user',
          content: userInput,
          timestamp: new Date()
        };
        messages = [...messages, userMessage];
        
        // Extract mentioned users from the input to count how many were queried
        const mentionRegex = /@(\w+)/g;
        const mentionMatches = userInput.match(mentionRegex) || [];
        const mentionedUsers = mentionMatches.map(match => match.substring(1)); // Remove @ symbol
        const uniqueMentionedUsers = [...new Set(mentionedUsers)]; // Remove duplicates
        const queriedCount = uniqueMentionedUsers.length;
        
        // Initialize responseMetadata for tracking responses
        const responseMetadata = {
          answeredCount: 0,
          queriedCount: queriedCount,
          isProcessing: true
        };
        
        // Create initial response message with processing indicator
        const responseMessageId = crypto.randomUUID();
        const initialResponseMessage: AIMessage = {
          id: responseMessageId,
          role: 'assistant',
          content: "Processing mentions...",
          timestamp: new Date(),
          isLoading: true,
          responseMetadata: responseMetadata // Add metadata for tracking
        };
        messages = [...messages, initialResponseMessage];
        
        // Function to fetch answers from the server
        const fetchAnswers = async () => {
          try {
            // Use POST with JSON body to ensure exact query matching
            const fetchUrl = `http://localhost:4232/answers`;
            
            // Prepare request with JSON body containing the exact query
            const requestBody = {
              query: userInput // Exact query string without any encoding or modification
            };
            
            // Enhanced logging for debugging
            console.log(`[MENTIONS_FETCH] Requesting answers via POST to: ${fetchUrl}`);
            console.log(`[MENTIONS_FETCH] Original query: "${userInput}"`);
            console.log(`[MENTIONS_FETCH] Request body: ${JSON.stringify(requestBody)}`);
            console.log(`[MENTIONS_FETCH] Timestamp: ${new Date().toISOString()}`);
            
            // Fetch options for POST request with JSON body
            const requestOptions = {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Accept': 'application/json'
              },
              body: JSON.stringify(requestBody)
            };
            
            console.log(`=========== ANSWER REQUEST DEBUG ===========`);
            console.log(`Request URL: ${fetchUrl}`);
            console.log(`Request method: POST`);
            console.log(`Request body: ${JSON.stringify(requestBody)}`);
            console.log(`=========== END DEBUG INFO ===========`);
            
            console.log(`[MENTIONS_FETCH] Sending POST request to ${fetchUrl}`);
            const startTime = Date.now();
            const response = await fetch(fetchUrl, requestOptions);
            const fetchTime = Date.now() - startTime;
            
            console.log(`[MENTIONS_FETCH] Response received in ${fetchTime}ms`);
            console.log(`[MENTIONS_FETCH] Response status: ${response.status} ${response.statusText}`);
            
            if (response.ok) {
              const contentType = response.headers.get('Content-Type');
              console.log(`[MENTIONS_FETCH] Response Content-Type: ${contentType}`);
              
              // Log the raw response text first
              const responseText = await response.text();
              console.log(`[MENTIONS_FETCH] Raw response: ${responseText.substring(0, 500)}${responseText.length > 500 ? '...' : ''}`);
              
              // Try to parse JSON
              let data;
              try {
                data = JSON.parse(responseText);
                console.log(`[MENTIONS_FETCH] Successfully parsed JSON response`);
                console.log(`[MENTIONS_FETCH] Received ${data.answers ? Object.keys(data.answers).length : 0} answers`);
                
                // Log the first few answers if available
                if (data.answers && Object.keys(data.answers).length > 0) {
                  console.log(`[MENTIONS_FETCH] Sample answers:`);
                  Object.entries(data.answers).slice(0, 3).forEach(([user, answer]) => {
                    console.log(`[MENTIONS_FETCH] - @${user}: ${typeof answer === 'string' ? answer.substring(0, 50) : 'Non-string answer'}...`);
                  });
                } else {
                  console.log(`[MENTIONS_FETCH] No answers found in the response`);
                  // Debug query string comparison issue
                  console.log(`[MENTIONS_FETCH] Query comparison check:`);
                  console.log(`[MENTIONS_FETCH] - Query sent: "${userInput}"`);
                  console.log(`[MENTIONS_FETCH] - Query from response: "${data.query || 'not provided'}"`);
                }
              } catch (parseError) {
                console.error(`[MENTIONS_FETCH] Failed to parse JSON: ${parseError.message}`);
                return null;
              }
              
              return data;
            } else {
              console.error(`[MENTIONS_FETCH] Request failed with status ${response.status}`);
              const errorText = await response.text();
              console.error(`[MENTIONS_FETCH] Error response: ${errorText}`);
              logger.error('Failed to fetch answers:', errorText);
              return null;
            }
          } catch (error) {
            console.error(`[MENTIONS_FETCH] Network or other error: ${error.message}`);
            console.error(`[MENTIONS_FETCH] Error stack: ${error.stack || 'No stack trace'}`);
            logger.error('Error fetching answers:', error);
            return null;
          }
        };
        
        // Set up periodic checking for responses
        let processingTime = 0;
        const checkInterval = 1000; // 1 second
        const maxProcessingTime = 10000; // 10 seconds
        
        // Function to update the processing animation
        const updateProcessingMessage = (newText: string, metadata: any) => {
          messages = messages.map(msg => {
            if (msg.id === responseMessageId) {
              return {
                ...msg,
                content: newText,
                responseMetadata: metadata
              };
            }
            return msg;
          });
        };
        
        // Start the processing animation with periodic checks
        const processingInterval = setInterval(async () => {
          processingTime += checkInterval;
          
          console.log(`[MENTIONS_POLL] Polling for answers (attempt #${processingTime / checkInterval})`);
          console.log(`[MENTIONS_POLL] Total processing time: ${processingTime}ms`);
          console.log(`[MENTIONS_POLL] Max processing time: ${maxProcessingTime}ms`);
          
          // Fetch current answers - use the EXACT query string without modification
          // The database expects the exact string that was sent in the remote message
          console.log(`[MENTIONS_POLL] Calling fetchAnswers()`);
          const answersData = await fetchAnswers();
          console.log(`[MENTIONS_POLL] fetchAnswers() returned: ${answersData ? 'Data object' : 'null'}`);
          
          if (answersData && answersData.answers) {
            // Update the number of answers received
            const currentAnswers = Object.keys(answersData.answers).length;
            responseMetadata.answeredCount = currentAnswers;
            
            console.log(`[MENTIONS_POLL] Found ${currentAnswers}/${queriedCount} answers`);
            console.log(`[MENTIONS_POLL] Answering users: ${Object.keys(answersData.answers).join(', ')}`);
            console.log(`[MENTIONS_POLL] Query used: "${answersData.query || 'not provided'}"`);
            
            // Update message with current status
            const processingDots = ".".repeat((processingTime / 1000) % 4);
            const statusText = `Processing mentions${processingDots}`;
            updateProcessingMessage(statusText, responseMetadata);
            console.log(`[MENTIONS_POLL] Updated processing message: "${statusText}"`);
            
            // If all users have answered or time is up, finish processing
            if (currentAnswers >= queriedCount || processingTime >= maxProcessingTime) {
              console.log(`[MENTIONS_POLL] Completing response: ${currentAnswers >= queriedCount ? 'All users answered' : 'Processing timeout reached'}`);
              console.log(`[MENTIONS_POLL] Final answers count: ${currentAnswers}/${queriedCount}`);
              clearInterval(processingInterval);
              
              // Get final response text with all possible fallbacks
              let responseText = "";
              
              // Format the answers into a readable response
              if (currentAnswers > 0) {
                console.log(`[MENTIONS_POLL] Formatting ${currentAnswers} answers for display`);
                responseText = "Responses received:\n\n";
                Object.entries(answersData.answers).forEach(([user, answer]) => {
                  console.log(`[MENTIONS_POLL] Adding answer from @${user}: ${typeof answer === 'string' ? answer.substring(0, 50) : 'Non-string answer'}...`);
                  responseText += `@${user}: ${answer}\n\n`;
                });
              } else {
                console.log(`[MENTIONS_POLL] No answers received, falling back to original mentionResult`);
                // No answers received, use the original mentionResult
                
                // Check for the wrapped response structure (from wrapIpcHandler)
                if (mentionResult && typeof mentionResult === 'object') {
                  if (mentionResult.success === true && mentionResult.data !== undefined) {
                    // Success response from IPC handler - unwrap the data
                    logger.debug('Found wrapped success response, unwrapping data');
                    
                    // The data property contains our actual result
                    const unwrappedResult = mentionResult.data;
                    
                    if (typeof unwrappedResult === 'string') {
                      // Direct string result
                      responseText = unwrappedResult;
                      logger.debug('Unwrapped result is string:', responseText);
                    } else if (typeof unwrappedResult === 'object' && unwrappedResult !== null) {
                      // Object result - try to find payload
                      if (unwrappedResult.payload !== undefined) {
                        responseText = typeof unwrappedResult.payload === 'string' ? 
                          unwrappedResult.payload : 
                          JSON.stringify(unwrappedResult.payload);
                        logger.debug('Using payload from unwrapped result:', responseText);
                      } else {
                        // Try to find any useful string
                        for (const key in unwrappedResult) {
                          if (typeof unwrappedResult[key] === 'string') {
                            responseText = unwrappedResult[key];
                            logger.debug(`Using ${key} from unwrapped result:`, responseText);
                            break;
                          }
                        }
                      }
                    }
                  } else if (mentionResult.success === false && mentionResult.error) {
                    // Error response from IPC handler
                    responseText = `Error: ${mentionResult.error.message || 'Unknown error'}`;
                    logger.debug('Found wrapped error response:', responseText);
                  } else if (mentionResult.payload !== undefined) {
                    // Direct result with payload property
                    responseText = typeof mentionResult.payload === 'string' ? 
                      mentionResult.payload : 
                      JSON.stringify(mentionResult.payload);
                    logger.debug('Found direct payload property:', responseText);
                  } else {
                    // Other types of objects - try properties directly
                    for (const key in mentionResult) {
                      if (typeof mentionResult[key] === 'string') {
                        responseText = mentionResult[key];
                        logger.debug(`Using property ${key} directly:`, responseText);
                        break;
                      }
                    }
                  }
                } else if (typeof mentionResult === 'string') {
                  // Direct string result
                  responseText = mentionResult;
                  logger.debug('Result is direct string:', responseText);
                } else if (!mentionResult) {
                  // Null or undefined result
                  responseText = "No responses received from mentioned users.";
                  logger.debug('mentionResult is null or undefined');
                }
              }
              
              // Update message with final response and mark as not loading
              responseMetadata.isProcessing = false;
              console.log(`[MENTIONS_POLL] Preparing final response update`);
              console.log(`[MENTIONS_POLL] Final response text length: ${responseText.length} characters`);
              console.log(`[MENTIONS_POLL] First 100 chars of response: "${responseText.substring(0, 100)}..."`);
              
              messages = messages.map(msg => {
                if (msg.id === responseMessageId) {
                  console.log(`[MENTIONS_POLL] Updating message ${msg.id} with final content`);
                  return {
                    ...msg,
                    content: responseText,
                    isLoading: false,
                    responseMetadata: responseMetadata
                  };
                }
                return msg;
              });
              
              // Save the updated chat history
              console.log(`[MENTIONS_POLL] Saving final chat history with updated message`);
              await saveAIChatHistory(messages);
              console.log(`[MENTIONS_POLL] Chat history saved successfully`);
            }
          } else {
            // Update with dots to show it's still processing
            const processingDots = ".".repeat((processingTime / 1000) % 4);
            const statusText = `Processing mentions${processingDots}`;
            updateProcessingMessage(statusText, responseMetadata);
            console.log(`[MENTIONS_POLL] Updated processing animation: "${statusText}"`);
            
            // If we've reached max time, finish processing
            if (processingTime >= maxProcessingTime) {
              console.log(`[MENTIONS_POLL] Maximum processing time reached (${maxProcessingTime}ms)`);
              console.log(`[MENTIONS_POLL] No answers data available, ending poll`);
              clearInterval(processingInterval);
              
              // Get response text with all possible fallbacks from original mentionResult
              let responseText = "Processing complete, but no responses were received.";
              console.log(`[MENTIONS_POLL] Using default timeout message: "${responseText}"`);
              
              // Similar fallback logic as before for mentionResult
              if (mentionResult && typeof mentionResult === 'object') {
                console.log(`[MENTIONS_POLL] Checking original mentionResult for fallback text`);
                console.log(`[MENTIONS_POLL] mentionResult type: ${typeof mentionResult}`);
                
                if (mentionResult.success === true && mentionResult.data !== undefined) {
                  console.log(`[MENTIONS_POLL] Found success:true response with data`);
                  const unwrappedResult = mentionResult.data;
                  console.log(`[MENTIONS_POLL] Unwrapped result type: ${typeof unwrappedResult}`);
                  
                  if (typeof unwrappedResult === 'string') {
                    responseText = unwrappedResult;
                    console.log(`[MENTIONS_POLL] Using string data from mentionResult: "${responseText.substring(0, 50)}..."`);
                  }
                  // ...other fallback logic
                }
              }
              
              // Update message with final response and mark as not loading
              responseMetadata.isProcessing = false;
              console.log(`[MENTIONS_POLL] Preparing final response update`);
              console.log(`[MENTIONS_POLL] Final response text length: ${responseText.length} characters`);
              console.log(`[MENTIONS_POLL] First 100 chars of response: "${responseText.substring(0, 100)}..."`);
              
              messages = messages.map(msg => {
                if (msg.id === responseMessageId) {
                  console.log(`[MENTIONS_POLL] Updating message ${msg.id} with final content`);
                  return {
                    ...msg,
                    content: responseText,
                    isLoading: false,
                    responseMetadata: responseMetadata
                  };
                }
                return msg;
              });
              
              // Save the updated chat history
              console.log(`[MENTIONS_POLL] Saving final chat history with updated message`);
              await saveAIChatHistory(messages);
              console.log(`[MENTIONS_POLL] Chat history saved successfully`);
            }
          }
        }, checkInterval);
        
        // Clear input
        newMessageText = '';
        
        // Exit the function - don't process as slash command or LLM query
        return;
      } catch (error) {
        logger.error('Error processing mentions:', error);
        window.api.toast.show('Error processing mentions', { type: 'error' });
        return;
      }
    }
    
    // 2. If no mentions, check if it's a slash command
    if (userInput.startsWith('/')) {
      // Handle as slash command (existing code will handle this)
      handleSimpleCommandExecute();
      return;
    }
    
    // Normal message processing flow - only executes if not returned earlier
    const userMessage: AIMessage = {
      id: crypto.randomUUID(),
      role: 'user',
      content: userInput,
      timestamp: new Date()
    }

    // Add user message to the chat
    messages = [...messages, userMessage]

    // Clear input field
    newMessageText = ''

    // Create a placeholder for the assistant's response
    const assistantPlaceholder: AIMessage = {
      id: crypto.randomUUID(),
      role: 'assistant',
      content: '',
      timestamp: new Date(),
      isLoading: true
    }

    messages = [...messages, assistantPlaceholder]
    isWaitingForResponse = true

    try {
      // Prepare the chat history to send to the LLM
      // Convert our UI messages to the format expected by the LLM API
      const chatHistory = messages
        .filter((msg) => msg.role === 'user' || (msg.role === 'assistant' && !msg.isLoading))
        .map((msg) => ({
          role: msg.role,
          content: msg.content
        }))

      // Generate a unique request ID for this conversation
      requestId = crypto.randomUUID()

      // Create a properly typed request
      const request: LLMTypes.ChatCompletionRequest = {
        messages: chatHistory,
        model: activeModel,
        stream: true
      }

      try {
        // Use the streaming API to get a response - this is a fire-and-forget operation
        // so we wrap it in try/catch but don't await it
        window.api.llm.streamMessage(requestId, request)

        // Save messages to database
        await saveAIChatHistory(messages)
      } catch (error) {
        // Handle streaming initiation error
        throw new AppError(
          error instanceof Error ? error.message : 'Failed to start AI message streaming',
          ErrorType.LLM_API
        )
      }
    } catch (error) {
      // Log the error
      logger.error('Error sending message to AI:', error)

      // Update the placeholder with an error message
      const errorMessage =
        error instanceof AppError
          ? error.message
          : error instanceof Error
            ? error.message
            : 'Unknown error occurred while processing your request'

      // Update the placeholder message with the error
      messages = messages.map((msg) => {
        if (msg.id === assistantPlaceholder.id) {
          return {
            ...msg,
            content: `I'm sorry, I encountered an error: ${errorMessage}`,
            isLoading: false
          }
        }
        return msg
      })

      isWaitingForResponse = false

      // Show error to user
      window.api.toast.show(`Error: ${errorMessage}`, { type: 'error' })

      // Save error state to database
      await saveAIChatHistory(messages)
    }
  }

  // Simple command handlers for the new approach
  function handleSimpleInputChange() {
    // Show command popup if input starts with /
    if (newMessageText.startsWith('/')) {
      showCommandPopup()
      userMentionPopupVisible = false
      logger.debug('Command mode activated. Text:', newMessageText)
    } else if (newMessageText.includes('@')) {
      // Check if we're in the middle of typing a mention
      const lastAtIndex = newMessageText.lastIndexOf('@');
      const textAfterAt = newMessageText.substring(lastAtIndex);
      
      // If there's a space after the @ symbol, or if the mention is complete, hide the popup
      if (textAfterAt.includes(' ') && textAfterAt.indexOf(' ') > 1) {
        // Mention is complete (there's a space after the username)
        userMentionPopupVisible = false;
        logger.debug('Mention complete, hiding popup');
      } else {
        // Still typing a mention, show popup
        hideCommandPopup();
        userMentionPopupVisible = true;
        logger.debug('User mention mode activated. Text:', newMessageText, 'Users count:', users.length);
      }
    } else {
      hideCommandPopup()
      userMentionPopupVisible = false
    }
  }

  function handleSimpleKeyPress(event: KeyboardEvent) {
    // Handle Enter key to execute command or send message
    if (event.key === 'Enter' && !event.shiftKey) {
      event.preventDefault()

      // Handle command if input starts with /
      if (newMessageText.trim().startsWith('/')) {
        handleSimpleCommandExecute()
      } else {
        sendMessage()
      }
      return
    }

    // Handle Tab key for command autocompletion
    if (event.key === 'Tab') {
      event.preventDefault()
      
      if (newMessageText.startsWith('/')) {
        // Autocomplete slash commands
        const filteredCmds = filterCommands(newMessageText)

        // If there are suggestions available, use the first one
        if (filteredCmds.length > 0) {
          const suggestion = filteredCmds[0]
          newMessageText = `/${suggestion.name} `

          // Set cursor position after the command and space
          setTimeout(() => {
            if (inputTextarea) {
              inputTextarea.focus()
              inputTextarea.selectionStart = suggestion.name.length + 2 // +2 for / and space
              inputTextarea.selectionEnd = suggestion.name.length + 2
            }
          }, 0)
        }
      } else if (newMessageText.includes('@')) {
        // Autocomplete user mentions
        const mentionText = newMessageText.substring(newMessageText.lastIndexOf('@') + 1)
        const filteredUsers = mentionText 
          ? users.filter(user => user.name.toLowerCase().includes(mentionText.toLowerCase())) 
          : users
          
        // If there are suggestions available, use the first one
        if (filteredUsers.length > 0) {
          const suggestion = filteredUsers[0]
          const beforeMention = newMessageText.substring(0, newMessageText.lastIndexOf('@'))
          const afterMention = newMessageText.substring(newMessageText.lastIndexOf('@') + mentionText.length + 1)
          
          newMessageText = `${beforeMention}@${suggestion.name} ${afterMention}`
          
          // Set cursor position after the mention and space
          setTimeout(() => {
            if (inputTextarea) {
              const cursorPos = beforeMention.length + suggestion.name.length + 2 // +2 for @ and space
              inputTextarea.focus()
              inputTextarea.selectionStart = cursorPos
              inputTextarea.selectionEnd = cursorPos
            }
          }, 0)
          
          // Hide the popup after selection
          userMentionPopupVisible = false
        }
      }
    }
    
    // Handle arrow keys for navigating mention suggestions
    if (userMentionPopupVisible && (event.key === 'ArrowDown' || event.key === 'ArrowUp')) {
      event.preventDefault()
      
      const mentionText = newMessageText.substring(newMessageText.lastIndexOf('@') + 1)
      const filteredUsers = mentionText 
        ? users.filter(user => user.name.toLowerCase().includes(mentionText.toLowerCase())) 
        : users
      
      if (filteredUsers.length > 0) {
        if (event.key === 'ArrowDown') {
          selectedUserIndex = (selectedUserIndex + 1) % filteredUsers.length
        } else {
          selectedUserIndex = selectedUserIndex <= 0 ? filteredUsers.length - 1 : selectedUserIndex - 1
        }
      }
    }
  }

  function handleSimpleCommandSelect(cmd: { name: string }) {
    newMessageText = `/${cmd.name} `

    if (inputTextarea) {
      inputTextarea.focus()

      // Set cursor position after the command and space
      setTimeout(() => {
        if (inputTextarea) {
          inputTextarea.selectionStart = cmd.name.length + 2 // +2 for / and space
          inputTextarea.selectionEnd = cmd.name.length + 2
        }
      }, 0)
    }
  }
  
  // Handle user selection from mention popup
  function handleUserSelect(user) {
    const mentionText = newMessageText.substring(newMessageText.lastIndexOf('@') + 1)
    const beforeMention = newMessageText.substring(0, newMessageText.lastIndexOf('@'))
    const afterMention = newMessageText.substring(newMessageText.lastIndexOf('@') + mentionText.length + 1)
    
    newMessageText = `${beforeMention}@${user.name} ${afterMention}`
    
    // Hide the popup after selection
    userMentionPopupVisible = false
    
    // Set cursor position after the mention and space
    if (inputTextarea) {
      setTimeout(() => {
        const cursorPos = beforeMention.length + user.name.length + 2 // +2 for @ and space
        inputTextarea.focus()
        inputTextarea.selectionStart = cursorPos
        inputTextarea.selectionEnd = cursorPos
      }, 0)
    }
  }

  async function handleSimpleCommandExecute() {
    const commandText = newMessageText.trim()
    logger.debug('Executing command:', commandText)

    // Add user message (the command) to chat
    const userMessage: AIMessage = {
      id: crypto.randomUUID(),
      role: 'user',
      content: commandText,
      timestamp: new Date()
    }

    messages = [...messages, userMessage]

    // Clear input field
    newMessageText = ''
    hideCommandPopup()

    try {
      // Show a loading indicator for the command execution
      const placeholderMessage: AIMessage = {
        id: crypto.randomUUID(),
        role: 'assistant',
        content: 'Processing command...',
        timestamp: new Date(),
        isLoading: true
      }

      messages = [...messages, placeholderMessage]

      // Execute the command (could be local or server-side)
      logger.debug(`Calling executeCommand with "${commandText}"`)
      const result = await executeCommand(commandText)

      // Check if this is a special LLM request result
      if (result && typeof result === 'object' && result.type === 'llm_request') {
        logger.debug('Received LLM request from command execution')

        // Update the placeholder message with the display text
        messages = messages.map((msg) => {
          if (msg.id === placeholderMessage.id) {
            logger.debug(`Found placeholder message, updating with LLM request display text`)
            return {
              ...msg,
              content: result.displayText,
              isLoading: true  // Keep loading while we start LLM request
            }
          }
          return msg
        })

        // Save the current messages state
        await saveAIChatHistory(messages)

        // Set waiting state for UI
        isWaitingForResponse = true
        logger.debug('Set isWaitingForResponse to true for LLM request')

        try {
          // Check if we have access to the LLM API
          if (!window.api?.llm?.streamMessage) {
            logger.error('LLM streaming API not available')
            throw new Error('LLM streaming API not available')
          }

          // Check active provider and model
          if (!activeProvider || !activeModel) {
            logger.error('No LLM provider or model configured', { activeProvider, activeModel })
            throw new Error('No AI provider or model configured. Please check your LLM settings.')
          }

          // Prepare the LLM request
          const llmRequest: LLMTypes.ChatCompletionRequest = {
            messages: result.messages,
            model: activeModel,
            stream: true
          }

          // Log the request details for debugging
          logger.debug(`Preparing LLM request with model: ${activeModel}`, {
            messageCount: result.messages.length,
            firstMessageSample: result.messages[0]?.content?.substring(0, 50) + '...'
          })

          // Generate a unique request ID for this conversation
          requestId = crypto.randomUUID()
          logger.debug(`Generated new requestId: ${requestId}`)

          // The isWaitingForResponse flag is already set

          // Use the streaming API to get a response
          logger.debug('Starting LLM request with messages from command')
          window.api.llm.streamMessage(requestId, llmRequest)
          logger.debug('LLM stream request sent successfully')

          // The rest will be handled by the streaming handlers
          return;
        } catch (llmError) {
          // Update the placeholder with an error message if the LLM request fails
          logger.error('Error starting LLM request from command:', llmError)

          messages = messages.map((msg) => {
            if (msg.id === placeholderMessage.id) {
              const errorMessage = llmError instanceof Error ? llmError.message : 'Unknown error';
              logger.error(`Error details: ${errorMessage}`);
              logger.debug(`Updating placeholder message ${msg.id} with error`)
              return {
                ...msg,
                content: result.displayText + `\n\nError: Failed to start AI processing: ${errorMessage}\nPlease try again.`,
                isLoading: false
              }
            }
            return msg
          })

          // Reset waiting state
          isWaitingForResponse = false;
        }
      } else {
        // Standard text result
        logger.debug(`Command execution result received with length: ${result ? result.length : 0}`)
        logger.debug(`First 100 chars: ${result ? result.substring(0, 100) : 'no result'}`)

        if (result && typeof result === 'string' && result.includes('Related Documents:')) {
          logger.debug('Result contains document references')
        }

        // Replace placeholder with result
        logger.debug(`Updating placeholder message ${placeholderMessage.id} with result`)
        messages = messages.map((msg) => {
          if (msg.id === placeholderMessage.id) {
            logger.debug(`Found placeholder message, updating content from "${msg.content}" to result`)
            return {
              ...msg,
              content: result,
              isLoading: false
            }
          }
          return msg
        })
      }

      // Special case for /clear command
      if (commandText.startsWith('/clear')) {
        await clearChat()
      }
    } catch (error) {
      // Handle error in command execution
      logger.error('Command execution failed:', error)

      // Add error message or update placeholder
      const errorMsg = `Error executing command: ${error instanceof Error ? error.message : 'Unknown error'}`

      // Check if we already have a placeholder to update
      const hasPlaceholder = messages.some((msg) => msg.isLoading)

      if (hasPlaceholder) {
        // Update placeholder with error
        messages = messages.map((msg) => {
          if (msg.isLoading) {
            return {
              ...msg,
              content: errorMsg,
              isLoading: false
            }
          }
          return msg
        })
      } else {
        // Add new error message
        messages = [
          ...messages,
          {
            id: crypto.randomUUID(),
            role: 'assistant',
            content: errorMsg,
            timestamp: new Date()
          }
        ]
      }
    }

    // Save the conversation
    logger.debug(`Saving chat history with ${messages.length} messages`)
    // Log content of the last message
    if (messages.length > 0) {
      const lastMsg = messages[messages.length - 1]
      logger.debug(`Last message (id: ${lastMsg.id}, role: ${lastMsg.role}) content length: ${lastMsg.content.length}`)
      logger.debug(`Last message first 100 chars: "${lastMsg.content.substring(0, 100)}"`)
    }
    await saveAIChatHistory(messages)
  }

  // Function to copy text to clipboard
  function copyToClipboard(text: string, messageId: string) {
    // Create a temporary object to track copy state
    const messageCopyState = { ...copyState }

    // Set this message's copy state to true (showing checkmark)
    messageCopyState[messageId] = true
    copyState = messageCopyState

    // Copy to clipboard
    navigator.clipboard.writeText(text).catch((err) => {
      console.error('Failed to copy text: ', err)
      window.api.toast.show('Failed to copy text to clipboard', { type: 'error' })
    })

    // Reset copy state after 2 seconds
    setTimeout(() => {
      const resetState = { ...copyState }
      resetState[messageId] = false
      copyState = resetState
    }, 2000)
  }

  // Track copy button states (for showing copy/check icons)
  let copyState: Record<string, boolean> = {}

  // Track modal states
  let showDropdown = false
  let showMCPModal = false

  // Document modal state
  let showDocumentModal = false
  let documentTitle = ''
  let documentContent = ''

  // Close dropdown when clicking outside
  function handleClickOutside(event: MouseEvent) {
    if (showDropdown) {
      showDropdown = false
    }
  }

  // Toggle dropdown menu visibility
  function toggleDropdown(event: MouseEvent) {
    event.stopPropagation() // Prevent event from bubbling up
    showDropdown = !showDropdown
  }

  // Handle document clicks to close dropdown
  onMount(() => {
    document.addEventListener('click', handleClickOutside)
  })

  onDestroy(() => {
    document.removeEventListener('click', handleClickOutside)
  })

  // Clear the chat history
  async function clearChat() {
    try {
      // Clear history via main process and get the welcome message back
      const success = await safeIpcCall(
        () => window.api.llm.clearAIChatHistory(),
        {
          show: (message, options) => window.api.toast.show(message, options)
        },
        'Failed to clear chat history'
      )

      if (success) {
        // Get the fresh history with just the welcome message
        const freshHistory = await safeIpcCall(() => window.api.llm.getAIChatHistory(), {
          show: (message, options) => window.api.toast.show(message, options)
        })
        messages = freshHistory
      } else {
        // Fallback if clearing fails (should not happen with the error handling)
        messages = [
          {
            id: crypto.randomUUID(),
            role: 'assistant',
            content: 'Chat history cleared. How can I help you today?',
            timestamp: new Date()
          }
        ]
        // Try to save the fallback message
        await saveAIChatHistory(messages)
      }
    } catch (error) {
      // Error already shown via toast from safeIpcCall
      logger.error('Failed to clear chat history:', error)

      // Still give user feedback by updating the UI, even if the server-side operation failed
      messages = [
        {
          id: crypto.randomUUID(),
          role: 'assistant',
          content:
            'I tried to clear the chat history but encountered an error. Let me know if you want to try again.',
          timestamp: new Date()
        }
      ]
    }
  }
</script>

<div class="flex flex-col h-full w-full">
  <div class="p-4 border-b border-border bg-background flex items-center justify-between">
    <div class="flex items-center gap-3">
      <div
        class="flex-shrink-0 w-8 h-8 bg-primary/10 rounded-full flex items-center justify-center text-sm font-medium text-primary"
      >
        <Bot size={18} />
      </div>
      <div>
        <h2 class="text-base font-semibold text-foreground">AI Assistant</h2>
        <p class="text-xs text-muted-foreground">
          {activeProvider && activeModel
            ? `Powered by ${activeProvider} - ${activeModel}`
            : 'No AI provider configured'}
        </p>
      </div>
    </div>
    <div class="relative">
      <button
        class="p-1.5 rounded-md text-muted-foreground hover:text-foreground hover:bg-muted/80 transition-colors"
        aria-label="Chat options"
        on:click={toggleDropdown}
      >
        <MoreVertical size={16} />
      </button>

      <!-- Dropdown menu -->
      {#if showDropdown}
        <div
          class="absolute right-0 z-10 w-40 rounded-md shadow-lg bg-popover border border-border"
          style="top: 2rem; right: 0;"
          on:click|stopPropagation
        >
          <div class="py-1">
            <button
              class="flex items-center gap-2 w-full px-4 py-2 text-sm hover:bg-muted/80 transition-colors"
              on:click={() => {
                showDropdown = false
                showMCPModal = true
              }}
            >
              <Server size={16} />
              MCP Servers
            </button>

            <hr class="my-1 border-border" />

            <button
              class="flex items-center gap-2 w-full px-4 py-2 text-sm text-destructive hover:bg-muted/80 transition-colors"
              on:click={() => {
                showDropdown = false
                clearChat()
              }}
            >
              <Trash2 size={16} />
              Clear History
            </button>
          </div>
        </div>
      {/if}
    </div>
  </div>

  <div
    bind:this={chatContainer}
    class="flex-1 p-4 overflow-y-auto flex flex-col gap-5 custom-scrollbar"
  >
    {#each messages as message (message.id)}
      <div class="flex flex-col gap-1">
        <div
          class={cn(
            'flex items-start gap-3 p-3 rounded-lg transition-colors group',
            message.role === 'assistant' ? 'hover:bg-muted/40' : 'hover:bg-muted/20'
          )}
        >
          <div
            class={cn(
              'flex-shrink-0 w-8 h-8 rounded-full flex items-center justify-center text-sm font-medium',
              message.role === 'assistant'
                ? 'bg-primary/10 text-primary'
                : 'bg-secondary text-secondary-foreground'
            )}
          >
            {#if message.role === 'assistant'}
              <Bot size={18} />
            {:else}
              <User size={18} />
            {/if}
          </div>
          <div class="flex-1 min-w-0">
            <div class="flex items-baseline justify-between">
              <div class="flex items-baseline gap-2">
                <span class="font-medium text-sm">
                  {message.role === 'assistant' ? 'AI Assistant' : 'You'}
                </span>
                <span class="text-xs text-muted-foreground flex items-center gap-2">
                  {formatMessageTimestamp(message.timestamp)}
                  
                  <!-- User response indicator -->
                  {#if message.responseMetadata && message.role === 'assistant'}
                    <span class="flex items-center text-xs bg-primary/10 px-2 py-0.5 rounded-full">
                      <User size={12} class="mr-1" />
                      {message.responseMetadata.answeredCount}/{message.responseMetadata.queriedCount}
                    </span>
                  {/if}
                </span>
              </div>

              <!-- Copy button for AI assistant messages only - visible on hover -->
              {#if message.role === 'assistant' && message.content && !message.isLoading}
                <button
                  class="text-muted-foreground hover:text-foreground transition-colors p-1 opacity-0 group-hover:opacity-100"
                  on:click={() => copyToClipboard(message.content, message.id)}
                  aria-label="Copy message"
                  title="Copy message"
                >
                  {#if copyState[message.id]}
                    <CheckCircle size={16} class="text-success" />
                  {:else}
                    <Copy size={16} />
                  {/if}
                </button>
              {/if}
            </div>

            {#if message.isLoading && message.content === ''}
              <div class="mt-1.5 flex items-center gap-2 text-muted-foreground">
                <LoaderCircle size={16} class="animate-spin" />
                <span class="text-sm">Thinking...</span>
              </div>
            {:else}
              <!-- Check if this is a document result message -->
              {#if message.content && message.content.includes('[DOCUMENT_RESULTS_START]') && message.content.includes('[DOCUMENT_RESULTS_END]')}
                {@const textParts = message.content.split('[DOCUMENT_RESULTS_START]')}
                {@const documentPart = message.content.substring(
                  message.content.indexOf('[DOCUMENT_RESULTS_START]') + '[DOCUMENT_RESULTS_START]'.length,
                  message.content.indexOf('[DOCUMENT_RESULTS_END]')
                )}
                {@const documents = (() => {
                  try {
                    return JSON.parse(documentPart);
                  } catch (e) {
                    console.error('Failed to parse document results', e);
                    return [];
                  }
                })()}

                <!-- Display the regular message content -->
                <div class="mt-1 text-sm text-foreground whitespace-pre-wrap">
                  {textParts[0]}
                </div>

                <!-- If we have document results, show document icon buttons -->
                {#if documents && documents.length > 0}
                  <div class="mt-3 flex flex-wrap gap-2">
                    <span class="text-xs text-muted-foreground mb-1 w-full">Related Documents:</span>
                    {#each documents as doc}
                      <button
                        class="inline-flex items-center gap-1.5 px-3 py-1.5 rounded-md bg-primary/10 hover:bg-primary/20 text-primary transition-colors text-xs border border-primary/20"
                        title={doc.title}
                        on:click={() => {
                          // Show the document in our custom modal
                          documentTitle = doc.title;
                          documentContent = doc.content;
                          showDocumentModal = true;
                        }}
                      >
                        <FileText size={14} />
                        {doc.title.length > 20 ? doc.title.substring(0, 20) + '...' : doc.title}
                      </button>
                    {/each}
                  </div>
                {/if}
              {:else}
                <!-- Regular message -->
                <div class="mt-1 text-sm text-foreground whitespace-pre-wrap">
                  {message.content}
                  {#if message.isLoading}
                    <LoaderCircle
                      size={16}
                      class="inline-block animate-spin ml-1 align-text-bottom"
                    />
                  {/if}
                </div>
              {/if}
            {/if}
          </div>
        </div>
      </div>
    {/each}
  </div>

  <div class="flex items-start gap-2 p-4 border-t border-border bg-background">
    <div class="flex-1 relative">
      <textarea
        bind:this={inputTextarea}
        class="block w-full px-3.5 py-2.5 rounded-md border border-border bg-background text-foreground text-sm focus:outline-none focus:border-primary resize-none min-h-[40px] max-h-[120px]"
        placeholder="Message AI Assistant... (type / for commands or @ to mention users)"
        bind:value={newMessageText}
        on:keydown={handleSimpleKeyPress}
        on:input={handleSimpleInputChange}
        disabled={isWaitingForResponse || !activeProvider}
        rows="1"
      ></textarea>

      <!-- Simple Command Popup -->
      <SimpleCommandPopup
        inputText={newMessageText}
        onSelectCommand={(cmd) => handleSimpleCommandSelect(cmd)}
      />
      
      <!-- User Mention Popup -->
      <UserMentionPopup
        inputText={newMessageText}
        visible={userMentionPopupVisible}
        users={users}
        selectedUserIndex={selectedUserIndex}
        currentUserId={userId}
        on:selectUser={(e) => handleUserSelect(e.detail)}
      />
    </div>

    <button
      class={cn(
        'self-stretch px-4 rounded-md border-none font-medium cursor-pointer flex items-center justify-center gap-2 min-w-[80px]',
        isWaitingForResponse || !newMessageText.trim() || !activeProvider
          ? 'bg-muted text-muted-foreground cursor-not-allowed'
          : 'bg-primary text-primary-foreground hover:bg-primary/90'
      )}
      on:click={sendMessage}
      disabled={isWaitingForResponse || !newMessageText.trim() || !activeProvider}
    >
      {#if isWaitingForResponse}
        <LoaderCircle size={16} class="animate-spin" />
      {:else}
        <span>Send</span>
        <ArrowRight size={16} />
      {/if}
    </button>
  </div>
</div>

<!-- MCP Servers Modal -->
<MCPServersModal bind:showModal={showMCPModal} on:close={() => (showMCPModal = false)} />

<!-- Document Modal -->
<DocumentModal
  bind:show={showDocumentModal}
  title={documentTitle}
  content={documentContent}
  on:close={() => (showDocumentModal = false)}
/>
